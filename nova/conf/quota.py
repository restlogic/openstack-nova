from bees import profiler as p
from oslo_config import cfg
quota_group = cfg.OptGroup(name='quota', title='Quota Options', help='\nQuota options allow to manage quotas in openstack deployment.\n')
quota_opts = [cfg.IntOpt('instances', min=-1, default=10, deprecated_group='DEFAULT', deprecated_name='quota_instances', help='\nThe number of instances allowed per project.\n\nPossible Values\n\n* A positive integer or 0.\n* -1 to disable the quota.\n'), cfg.IntOpt('cores', min=-1, default=20, deprecated_group='DEFAULT', deprecated_name='quota_cores', help='\nThe number of instance cores or vCPUs allowed per project.\n\nPossible values:\n\n* A positive integer or 0.\n* -1 to disable the quota.\n'), cfg.IntOpt('ram', min=-1, default=50 * 1024, deprecated_group='DEFAULT', deprecated_name='quota_ram', help='\nThe number of megabytes of instance RAM allowed per project.\n\nPossible values:\n\n* A positive integer or 0.\n* -1 to disable the quota.\n'), cfg.IntOpt('metadata_items', min=-1, default=128, deprecated_group='DEFAULT', deprecated_name='quota_metadata_items', help='\nThe number of metadata items allowed per instance.\n\nUsers can associate metadata with an instance during instance creation. This\nmetadata takes the form of key-value pairs.\n\nPossible values:\n\n* A positive integer or 0.\n* -1 to disable the quota.\n'), cfg.IntOpt('injected_files', min=-1, default=5, deprecated_group='DEFAULT', deprecated_name='quota_injected_files', help='\nThe number of injected files allowed.\n\nFile injection allows users to customize the personality of an instance by\ninjecting data into it upon boot. Only text file injection is permitted: binary\nor ZIP files are not accepted. During file injection, any existing files that\nmatch specified files are renamed to include ``.bak`` extension appended with a\ntimestamp.\n\nPossible values:\n\n* A positive integer or 0.\n* -1 to disable the quota.\n'), cfg.IntOpt('injected_file_content_bytes', min=-1, default=10 * 1024, deprecated_group='DEFAULT', deprecated_name='quota_injected_file_content_bytes', help='\nThe number of bytes allowed per injected file.\n\nPossible values:\n\n* A positive integer or 0.\n* -1 to disable the quota.\n'), cfg.IntOpt('injected_file_path_length', min=-1, default=255, deprecated_group='DEFAULT', deprecated_name='quota_injected_file_path_length', help='\nThe maximum allowed injected file path length.\n\nPossible values:\n\n* A positive integer or 0.\n* -1 to disable the quota.\n'), cfg.IntOpt('key_pairs', min=-1, default=100, deprecated_group='DEFAULT', deprecated_name='quota_key_pairs', help='\nThe maximum number of key pairs allowed per user.\n\nUsers can create at least one key pair for each project and use the key pair\nfor multiple instances that belong to that project.\n\nPossible values:\n\n* A positive integer or 0.\n* -1 to disable the quota.\n'), cfg.IntOpt('server_groups', min=-1, default=10, deprecated_group='DEFAULT', deprecated_name='quota_server_groups', help='\nThe maxiumum number of server groups per project.\n\nServer groups are used to control the affinity and anti-affinity scheduling\npolicy for a group of servers or instances. Reducing the quota will not affect\nany existing group, but new servers will not be allowed into groups that have\nbecome over quota.\n\nPossible values:\n\n* A positive integer or 0.\n* -1 to disable the quota.\n'), cfg.IntOpt('server_group_members', min=-1, default=10, deprecated_group='DEFAULT', deprecated_name='quota_server_group_members', help='\nThe maximum number of servers per server group.\n\nPossible values:\n\n* A positive integer or 0.\n* -1 to disable the quota.\n'), cfg.StrOpt('driver', default='nova.quota.DbQuotaDriver', choices=[('nova.quota.DbQuotaDriver', 'Stores quota limit information in the database and relies on the ``quota_*`` configuration options for default quota limit values. Counts quota usage on-demand.'), ('nova.quota.NoopQuotaDriver', 'Ignores quota and treats all resources as unlimited.')], help='\nProvides abstraction for quota checks. Users can configure a specific\ndriver to use for quota checks.\n'), cfg.BoolOpt('recheck_quota', default=True, help='\nRecheck quota after resource creation to prevent allowing quota to be exceeded.\n\nThis defaults to True (recheck quota after resource creation) but can be set to\nFalse to avoid additional load if allowing quota to be exceeded because of\nracing requests is considered acceptable. For example, when set to False, if a\nuser makes highly parallel REST API requests to create servers, it will be\npossible for them to create more servers than their allowed quota during the\nrace. If their quota is 10 servers, they might be able to create 50 during the\nburst. After the burst, they will not be able to create any more servers but\nthey will be able to keep their 50 servers until they delete them.\n\nThe initial quota check is done before resources are created, so if multiple\nparallel requests arrive at the same time, all could pass the quota check and\ncreate resources, potentially exceeding quota. When recheck_quota is True,\nquota will be checked a second time after resources have been created and if\nthe resource is over quota, it will be deleted and OverQuota will be raised,\nusually resulting in a 403 response to the REST API user. This makes it\nimpossible for a user to exceed their quota with the caveat that it will,\nhowever, be possible for a REST API user to be rejected with a 403 response in\nthe event of a collision close to reaching their quota limit, even if the user\nhas enough quota available when they made the request.\n'), cfg.BoolOpt('count_usage_from_placement', default=False, help='\nEnable the counting of quota usage from the placement service.\n\nStarting in Train, it is possible to count quota usage for cores and ram from\nthe placement service and instances from the API database instead of counting\nfrom cell databases.\n\nThis works well if there is only one Nova deployment running per placement\ndeployment. However, if an operator is running more than one Nova deployment\nsharing a placement deployment, they should not set this option to True because\ncurrently the placement service has no way to partition resource providers per\nNova deployment. When this option is left as the default or set to False, Nova\nwill use the legacy counting method to count quota usage for instances, cores,\nand ram from its cell databases.\n\nNote that quota usage behavior related to resizes will be affected if this\noption is set to True. Placement resource allocations are claimed on the\ndestination while holding allocations on the source during a resize, until the\nresize is confirmed or reverted. During this time, when the server is in\nVERIFY_RESIZE state, quota usage will reflect resource consumption on both the\nsource and the destination. This can be beneficial as it reserves space for a\nrevert of a downsize, but it also means quota usage will be inflated until a\nresize is confirmed or reverted.\n\nBehavior will also be different for unscheduled servers in ERROR state. A\nserver in ERROR state that has never been scheduled to a compute host will\nnot have placement allocations, so it will not consume quota usage for cores\nand ram.\n\nBehavior will be different for servers in SHELVED_OFFLOADED state. A server in\nSHELVED_OFFLOADED state will not have placement allocations, so it will not\nconsume quota usage for cores and ram. Note that because of this, it will be\npossible for a request to unshelve a server to be rejected if the user does not\nhave enough quota available to support the cores and ram needed by the server\nto be unshelved.\n\nThe ``populate_queued_for_delete`` and ``populate_user_id`` online data\nmigrations must be completed before usage can be counted from placement. Until\nthe data migration is complete, the system will fall back to legacy quota usage\ncounting from cell databases depending on the result of an EXISTS database\nquery during each quota check, if this configuration option is set to True.\nOperators who want to avoid the performance hit from the EXISTS queries should\nwait to set this configuration option to True until after they have completed\ntheir online data migrations via ``nova-manage db online_data_migrations``.\n')]

@p.trace('register_opts')
def register_opts(conf):
    conf.register_group(quota_group)
    conf.register_opts(quota_opts, group=quota_group)

@p.trace('list_opts')
def list_opts():
    return {quota_group: quota_opts}